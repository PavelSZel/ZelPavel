{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting natasha\n",
      "  Downloading natasha-1.6.0-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from natasha) (0.9.1)\n",
      "Collecting razdel>=0.5.0 (from natasha)\n",
      "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting navec>=0.9.0 (from natasha)\n",
      "  Downloading navec-0.10.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting slovnet>=0.6.0 (from natasha)\n",
      "  Downloading slovnet-0.6.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting yargy>=0.16.0 (from natasha)\n",
      "  Downloading yargy-0.16.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting ipymarkup>=0.8.0 (from natasha)\n",
      "  Downloading ipymarkup-0.9.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: intervaltree>=3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from navec>=0.9.0->natasha) (1.26.4)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pymorphy2->natasha) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pymorphy2->natasha) (0.6.2)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
      "Downloading natasha-1.6.0-py3-none-any.whl (34.4 MB)\n",
      "   ---------------------------------------- 0.0/34.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/34.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/34.4 MB 2.9 MB/s eta 0:00:12\n",
      "    --------------------------------------- 0.5/34.4 MB 4.3 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.1/34.4 MB 6.4 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 1.7/34.4 MB 7.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.5/34.4 MB 9.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 3.5/34.4 MB 11.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 4.4/34.4 MB 12.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 5.5/34.4 MB 13.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 6.7/34.4 MB 14.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 7.6/34.4 MB 15.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 8.8/34.4 MB 16.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 9.9/34.4 MB 16.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 11.1/34.4 MB 20.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 12.1/34.4 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 13.4/34.4 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 14.6/34.4 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 15.5/34.4 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 16.2/34.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 17.4/34.4 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 18.8/34.4 MB 24.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 20.0/34.4 MB 24.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 20.6/34.4 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 21.9/34.4 MB 21.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 23.3/34.4 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 24.5/34.4 MB 23.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 25.8/34.4 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 26.6/34.4 MB 25.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 27.8/34.4 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 29.0/34.4 MB 25.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 30.4/34.4 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 31.8/34.4 MB 27.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 32.8/34.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  34.4/34.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  34.4/34.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  34.4/34.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 34.4/34.4 MB 21.1 MB/s eta 0:00:00\n",
      "Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
      "Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
      "Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
      "Downloading slovnet-0.6.0-py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.7/46.7 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading yargy-0.16.0-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: razdel, navec, yargy, slovnet, ipymarkup, natasha\n",
      "Successfully installed ipymarkup-0.9.0 natasha-1.6.0 navec-0.10.0 razdel-0.5.0 slovnet-0.6.0 yargy-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "4Vf3oAzb8pYt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from natasha import Segmenter, NewsEmbedding, NewsMorphTagger, MorphVocab, Doc\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RyV4PQML9Rif"
   },
   "outputs": [],
   "source": [
    "# Загрузим и сразу подготовим тестовые данные\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "sample = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "test = pd.merge(test_data, sample, on='oid', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bldQ4vqI9c7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38740, 2)\n",
      "                                                text  labels\n",
      "0  Волшебные фото Виктория Поплавская ЕвгенияМедв...      12\n",
      "1  Возвращение в подземелье Треша 33 Эйфория тупо...       5\n",
      "2  Лучшие чешские вратари – Доминик Доминатор Гаш...       6\n",
      "\n",
      "(26260, 2)\n",
      "                                                text  labels\n",
      "0  СПОЧНО СООБЩЕСТВО ПРОДАЕТСЯ ЗА 1300Р ЗА ПОКУПК...       4\n",
      "1  Естественное восстановление после тяжелой трен...       8\n",
      "2  Тема нарядов продолжается Одна из британских ж...      10\n"
     ]
    }
   ],
   "source": [
    "# Закодируем целевую переменную и удалим лишние столбцы\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train['labels'] = le.fit_transform(train['category'])\n",
    "test['labels'] = le.transform(test['category'])\n",
    "\n",
    "train = train.drop(columns=['oid', 'category'])\n",
    "test = test.drop(columns=['oid', 'category'])\n",
    "\n",
    "print(train.shape)\n",
    "print(train.head(3))\n",
    "print()\n",
    "print(test.shape)\n",
    "print(test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CBQ-CYWz9noc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35965, 2)\n",
      "(24936, 2)\n"
     ]
    }
   ],
   "source": [
    "# Избавимся от дубликатов\n",
    "\n",
    "train.drop_duplicates(inplace=True)\n",
    "test.drop_duplicates(inplace=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "94FfcaWA-Id1"
   },
   "outputs": [],
   "source": [
    "# Инициализируем инструменты, создадим функцию для обработки текста\n",
    "\n",
    "segmenter = Segmenter()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "def lemmatize(text):\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "    lemmas = [token.lemma.lower() for token in doc.tokens if token.lemma.isalpha()]\n",
    "    return  ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZQTNQYqf-Jhc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Волшебные фото Виктория Поплавская ЕвгенияМедв...</td>\n",
       "      <td>12</td>\n",
       "      <td>волшебный фото виктория поплавский евгениямедв...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Возвращение в подземелье Треша 33 Эйфория тупо...</td>\n",
       "      <td>5</td>\n",
       "      <td>возвращение в подземелье треш эйфория тупость ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Лучшие чешские вратари – Доминик Доминатор Гаш...</td>\n",
       "      <td>6</td>\n",
       "      <td>хороший чешский вратарь доминик доминатор гаше...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rtokenoid Warhammer40k валрак решил нас подкор...</td>\n",
       "      <td>3</td>\n",
       "      <td>rtokenoid warhammer k валрак решить мы подкорм...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Шестеркин затаскивает Рейнджерс в финал Восточ...</td>\n",
       "      <td>7</td>\n",
       "      <td>шестеркин затаскивает рейнджерс в финал восточ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels  \\\n",
       "0  Волшебные фото Виктория Поплавская ЕвгенияМедв...      12   \n",
       "1  Возвращение в подземелье Треша 33 Эйфория тупо...       5   \n",
       "2  Лучшие чешские вратари – Доминик Доминатор Гаш...       6   \n",
       "3  Rtokenoid Warhammer40k валрак решил нас подкор...       3   \n",
       "4  Шестеркин затаскивает Рейнджерс в финал Восточ...       7   \n",
       "\n",
       "                                                lemm  \n",
       "0  волшебный фото виктория поплавский евгениямедв...  \n",
       "1  возвращение в подземелье треш эйфория тупость ...  \n",
       "2  хороший чешский вратарь доминик доминатор гаше...  \n",
       "3  rtokenoid warhammer k валрак решить мы подкорм...  \n",
       "4  шестеркин затаскивает рейнджерс в финал восточ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обработаем текст\n",
    "\n",
    "train['lemm'] = train['text'].apply(lemmatize)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AfwhT7kD-Q5i"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>СПОЧНО СООБЩЕСТВО ПРОДАЕТСЯ ЗА 1300Р ЗА ПОКУПК...</td>\n",
       "      <td>4</td>\n",
       "      <td>спочно сообщество продаваться за р за покупка ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Естественное восстановление после тяжелой трен...</td>\n",
       "      <td>8</td>\n",
       "      <td>естественный восстановление после тяжелый трен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Тема нарядов продолжается Одна из британских ж...</td>\n",
       "      <td>10</td>\n",
       "      <td>тема наряд продолжаться один из британский жур...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Привет Избранный. Ты спрашиваешь себя ЧТО здес...</td>\n",
       "      <td>4</td>\n",
       "      <td>привет избранный ты спрашивать себя что здесь ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>КОРОЛЬ ПЯТИСОТНИКОВ В ДЕЛЕ Андрей Рублев успеш...</td>\n",
       "      <td>10</td>\n",
       "      <td>король пятисотник в дело андрей рублев успешно...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels  \\\n",
       "0  СПОЧНО СООБЩЕСТВО ПРОДАЕТСЯ ЗА 1300Р ЗА ПОКУПК...       4   \n",
       "1  Естественное восстановление после тяжелой трен...       8   \n",
       "2  Тема нарядов продолжается Одна из британских ж...      10   \n",
       "3  Привет Избранный. Ты спрашиваешь себя ЧТО здес...       4   \n",
       "4  КОРОЛЬ ПЯТИСОТНИКОВ В ДЕЛЕ Андрей Рублев успеш...      10   \n",
       "\n",
       "                                                lemm  \n",
       "0  спочно сообщество продаваться за р за покупка ...  \n",
       "1  естественный восстановление после тяжелый трен...  \n",
       "2  тема наряд продолжаться один из британский жур...  \n",
       "3  привет избранный ты спрашивать себя что здесь ...  \n",
       "4  король пятисотник в дело андрей рублев успешно...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['lemm'] = test['text'].apply(lemmatize)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "G0qy_SaK-TAZ"
   },
   "outputs": [],
   "source": [
    "# Разделим данные для обучением, векторизуем текст\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(train['lemm'])\n",
    "y_train = train['labels']\n",
    "X_test = vectorizer.transform(test['lemm'])\n",
    "y_test = test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Xd57nw-F_GcN"
   },
   "outputs": [],
   "source": [
    "# Обучим модели\n",
    "\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "rf = RandomForestClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kuabmjyl_Q7P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   athletics       0.94      0.78      0.85      2085\n",
      "   autosport       0.91      0.82      0.86      1907\n",
      "  basketball       0.89      0.84      0.87      1711\n",
      "  boardgames       0.93      0.92      0.92      1795\n",
      "      esport       0.75      0.85      0.79      1855\n",
      "     extreme       0.64      0.76      0.69      1866\n",
      "    football       0.76      0.83      0.79      1805\n",
      "      hockey       0.88      0.81      0.84      2120\n",
      "martial_arts       0.72      0.88      0.79      1650\n",
      "   motosport       0.92      0.91      0.91      1850\n",
      "      tennis       0.97      0.93      0.95      2002\n",
      "  volleyball       0.91      0.81      0.86      2129\n",
      "winter_sport       0.87      0.87      0.87      2161\n",
      "\n",
      "    accuracy                           0.85     24936\n",
      "   macro avg       0.85      0.85      0.85     24936\n",
      "weighted avg       0.86      0.85      0.85     24936\n",
      "\n",
      "Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   athletics       0.91      0.81      0.86      2085\n",
      "   autosport       0.85      0.81      0.83      1907\n",
      "  basketball       0.85      0.77      0.81      1711\n",
      "  boardgames       0.91      0.92      0.92      1795\n",
      "      esport       0.67      0.77      0.72      1855\n",
      "     extreme       0.62      0.69      0.66      1866\n",
      "    football       0.66      0.77      0.71      1805\n",
      "      hockey       0.83      0.76      0.80      2120\n",
      "martial_arts       0.70      0.81      0.75      1650\n",
      "   motosport       0.90      0.90      0.90      1850\n",
      "      tennis       0.92      0.93      0.92      2002\n",
      "  volleyball       0.91      0.78      0.84      2129\n",
      "winter_sport       0.85      0.80      0.83      2161\n",
      "\n",
      "    accuracy                           0.81     24936\n",
      "   macro avg       0.82      0.81      0.81     24936\n",
      "weighted avg       0.82      0.81      0.81     24936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверим метрики\n",
    "\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, lr.predict(X_test), target_names=le.classes_))\n",
    "print(\"Random Forest:\\n\", classification_report(y_test, rf.predict(X_test), target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vector', vectorizer),\n",
    "    ('model', lr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "-iDbTDPk_Yvj"
   },
   "outputs": [],
   "source": [
    "with open('LogRegModel.dill', 'wb') as file:\n",
    "    dill.dump(pipeline, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "SokmZeRE_iRY"
   },
   "outputs": [],
   "source": [
    "# Проверим работу локально\n",
    "\n",
    "text_test = 'Отличный прыжок нашего спортсмена со снаряда, идеальное приземление'\n",
    "text_test2 = 'Медведев закончил игру подачей навылет. Гейм, сет, матч'\n",
    "\n",
    "def predict(text):\n",
    "    text = lemmatize(text)\n",
    "    predict = pipeline.predict([text])\n",
    "    return le.inverse_transform(predict)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "KoTcdZ6o_oP9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volleyball\n",
      "\n",
      "tennis\n"
     ]
    }
   ],
   "source": [
    "# Проверим ответ модели\n",
    "\n",
    "print(predict(text_test))\n",
    "print()\n",
    "print(predict(text_test2))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
